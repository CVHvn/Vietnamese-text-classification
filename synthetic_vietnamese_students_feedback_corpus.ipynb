{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d39044d",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.015557,
          "end_time": "2024-06-24T11:53:32.877483",
          "exception": false,
          "start_time": "2024-06-24T11:53:32.861926",
          "status": "completed"
        },
        "tags": [],
        "id": "9d39044d"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc83df1e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:53:32.908413Z",
          "iopub.status.busy": "2024-06-24T11:53:32.908110Z",
          "iopub.status.idle": "2024-06-24T11:54:10.387490Z",
          "shell.execute_reply": "2024-06-24T11:54:10.386510Z"
        },
        "papermill": {
          "duration": 37.497447,
          "end_time": "2024-06-24T11:54:10.389921",
          "exception": false,
          "start_time": "2024-06-24T11:53:32.892474",
          "status": "completed"
        },
        "tags": [],
        "id": "bc83df1e",
        "outputId": "7e7be6ba-f156-4703-9176-67ad18884bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.1)\r\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\r\n",
            "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\r\n",
            "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\r\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\r\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\r\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\r\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\r\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n"
          ]
        }
      ],
      "source": [
        "!pip install -u pandas\n",
        "!pip install -u scikit-learn\n",
        "!pip install -u transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdf78a33",
      "metadata": {
        "papermill": {
          "duration": 0.015561,
          "end_time": "2024-06-24T11:54:10.422648",
          "exception": false,
          "start_time": "2024-06-24T11:54:10.407087",
          "status": "completed"
        },
        "tags": [],
        "id": "fdf78a33"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a73d3e7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:10.455170Z",
          "iopub.status.busy": "2024-06-24T11:54:10.454788Z",
          "iopub.status.idle": "2024-06-24T11:54:17.007150Z",
          "shell.execute_reply": "2024-06-24T11:54:17.006175Z"
        },
        "papermill": {
          "duration": 6.571427,
          "end_time": "2024-06-24T11:54:17.009529",
          "exception": false,
          "start_time": "2024-06-24T11:54:10.438102",
          "status": "completed"
        },
        "tags": [],
        "id": "a73d3e7c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor, nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8262f5e9",
      "metadata": {
        "papermill": {
          "duration": 0.01539,
          "end_time": "2024-06-24T11:54:17.040931",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.025541",
          "status": "completed"
        },
        "tags": [],
        "id": "8262f5e9"
      },
      "source": [
        "# Define hyperparammeter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e57043",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.073445Z",
          "iopub.status.busy": "2024-06-24T11:54:17.072931Z",
          "iopub.status.idle": "2024-06-24T11:54:17.077275Z",
          "shell.execute_reply": "2024-06-24T11:54:17.076425Z"
        },
        "papermill": {
          "duration": 0.023061,
          "end_time": "2024-06-24T11:54:17.079379",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.056318",
          "status": "completed"
        },
        "tags": [],
        "id": "74e57043"
      },
      "outputs": [],
      "source": [
        "epochs = 4\n",
        "batch_size = 16\n",
        "init_lr = 2e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0e7159",
      "metadata": {
        "papermill": {
          "duration": 0.015248,
          "end_time": "2024-06-24T11:54:17.109911",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.094663",
          "status": "completed"
        },
        "tags": [],
        "id": "1d0e7159"
      },
      "source": [
        "# Sentiment\n",
        "First we finetune model to predict sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e44a9f5",
      "metadata": {
        "papermill": {
          "duration": 0.015384,
          "end_time": "2024-06-24T11:54:17.140527",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.125143",
          "status": "completed"
        },
        "tags": [],
        "id": "7e44a9f5"
      },
      "source": [
        "## load data\n",
        "I download dataset from [kaggle](https://www.kaggle.com/datasets/toreleon/synthetic-vietnamese-students-feedback-corpus/data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73eb1b6a",
      "metadata": {
        "papermill": {
          "duration": 0.015185,
          "end_time": "2024-06-24T11:54:17.171035",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.155850",
          "status": "completed"
        },
        "tags": [],
        "id": "73eb1b6a"
      },
      "source": [
        "### Read csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f37d3a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.202805Z",
          "iopub.status.busy": "2024-06-24T11:54:17.202402Z",
          "iopub.status.idle": "2024-06-24T11:54:17.270570Z",
          "shell.execute_reply": "2024-06-24T11:54:17.269832Z"
        },
        "papermill": {
          "duration": 0.086176,
          "end_time": "2024-06-24T11:54:17.272390",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.186214",
          "status": "completed"
        },
        "tags": [],
        "id": "5f37d3a0"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/kaggle/input/synthetic-vietnamese-students-feedback-corpus/synthetic_train.csv\")\n",
        "df_test = pd.read_csv(\"/kaggle/input/synthetic-vietnamese-students-feedback-corpus/synthetic_val.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "453549c0",
      "metadata": {
        "papermill": {
          "duration": 0.015076,
          "end_time": "2024-06-24T11:54:17.302915",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.287839",
          "status": "completed"
        },
        "tags": [],
        "id": "453549c0"
      },
      "source": [
        "### Review data\n",
        "- Dataset have three column sentence and sentiment. We will use sentence as input and sentiment is output.\n",
        "- We can see that this data is belance because all classes have same number of samples.\n",
        "- Then, we count number words in each sentence. We can see that max word is 48. We don't need use large input size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67559b95",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.334703Z",
          "iopub.status.busy": "2024-06-24T11:54:17.334378Z",
          "iopub.status.idle": "2024-06-24T11:54:17.352279Z",
          "shell.execute_reply": "2024-06-24T11:54:17.351438Z"
        },
        "papermill": {
          "duration": 0.036052,
          "end_time": "2024-06-24T11:54:17.354261",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.318209",
          "status": "completed"
        },
        "tags": [],
        "id": "67559b95",
        "outputId": "9280ff9f-fb13-46ba-a07b-9d0e140d7336"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The university's musical and artistic faciliti...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Phương pháp giảng dạy phù hợp với các đối tượn...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chương trình học giúp tôi trở thành một chuyên...</td>\n",
              "      <td>positive</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tôi nghĩ rằng chương trình đào tạo có thể có t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0  Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...  negative    facility\n",
              "1  The university's musical and artistic faciliti...   neutral    facility\n",
              "2  Phương pháp giảng dạy phù hợp với các đối tượn...   neutral  curriculum\n",
              "3  Chương trình học giúp tôi trở thành một chuyên...  positive  curriculum\n",
              "4  Tôi nghĩ rằng chương trình đào tạo có thể có t...   neutral  curriculum"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eeb1011",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.386897Z",
          "iopub.status.busy": "2024-06-24T11:54:17.386619Z",
          "iopub.status.idle": "2024-06-24T11:54:17.395009Z",
          "shell.execute_reply": "2024-06-24T11:54:17.394184Z"
        },
        "papermill": {
          "duration": 0.026806,
          "end_time": "2024-06-24T11:54:17.396932",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.370126",
          "status": "completed"
        },
        "tags": [],
        "id": "1eeb1011",
        "outputId": "1599622c-24e6-4539-8b71-05aec3d34860"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chất lượng vật chất kém.</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Phần mềm học tập quá khó sử dụng, khiến sinh v...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trường tôi thiếu những tiện ích cơ bản như máy...</td>\n",
              "      <td>negative</td>\n",
              "      <td>facility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cần tạo thêm các hoạt động gắn kết giữa sinh v...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Họ rất khoan dung và lượng giác trong quan điể...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment       topic\n",
              "0                           Chất lượng vật chất kém.  negative    facility\n",
              "1  Phần mềm học tập quá khó sử dụng, khiến sinh v...  negative    facility\n",
              "2  Trường tôi thiếu những tiện ích cơ bản như máy...  negative    facility\n",
              "3  Cần tạo thêm các hoạt động gắn kết giữa sinh v...   neutral  curriculum\n",
              "4  Họ rất khoan dung và lượng giác trong quan điể...   neutral      others"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc71129",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.429988Z",
          "iopub.status.busy": "2024-06-24T11:54:17.429730Z",
          "iopub.status.idle": "2024-06-24T11:54:17.443285Z",
          "shell.execute_reply": "2024-06-24T11:54:17.442469Z"
        },
        "papermill": {
          "duration": 0.032243,
          "end_time": "2024-06-24T11:54:17.445168",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.412925",
          "status": "completed"
        },
        "tags": [],
        "id": "abc71129",
        "outputId": "f8cafe8d-f6c1-42ba-9a7a-ca45cfd877a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     2724\n",
              "negative    2711\n",
              "positive    2709\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855ce0b5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.478342Z",
          "iopub.status.busy": "2024-06-24T11:54:17.478040Z",
          "iopub.status.idle": "2024-06-24T11:54:17.484565Z",
          "shell.execute_reply": "2024-06-24T11:54:17.483764Z"
        },
        "papermill": {
          "duration": 0.025279,
          "end_time": "2024-06-24T11:54:17.486500",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.461221",
          "status": "completed"
        },
        "tags": [],
        "id": "855ce0b5",
        "outputId": "32c2092d-ed8b-4293-d360-c6d18115d884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    686\n",
              "positive    680\n",
              "neutral     670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acbb35e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.519818Z",
          "iopub.status.busy": "2024-06-24T11:54:17.519550Z",
          "iopub.status.idle": "2024-06-24T11:54:17.545756Z",
          "shell.execute_reply": "2024-06-24T11:54:17.544946Z"
        },
        "papermill": {
          "duration": 0.045052,
          "end_time": "2024-06-24T11:54:17.547778",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.502726",
          "status": "completed"
        },
        "tags": [],
        "id": "5acbb35e"
      },
      "outputs": [],
      "source": [
        "df_train['len'] = df_train.sentence.apply(lambda x: len(str(x).split()))\n",
        "df_test['len'] = df_test.sentence.apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16032d0f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.581116Z",
          "iopub.status.busy": "2024-06-24T11:54:17.580856Z",
          "iopub.status.idle": "2024-06-24T11:54:17.592708Z",
          "shell.execute_reply": "2024-06-24T11:54:17.591608Z"
        },
        "papermill": {
          "duration": 0.030862,
          "end_time": "2024-06-24T11:54:17.594702",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.563840",
          "status": "completed"
        },
        "tags": [],
        "id": "16032d0f",
        "outputId": "c936a53f-29b8-4691-eb6e-68c57aa3afff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8144.000000\n",
              "mean       15.549730\n",
              "std         5.018764\n",
              "min         3.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        43.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['len'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c9ee85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.628453Z",
          "iopub.status.busy": "2024-06-24T11:54:17.628135Z",
          "iopub.status.idle": "2024-06-24T11:54:17.636983Z",
          "shell.execute_reply": "2024-06-24T11:54:17.636144Z"
        },
        "papermill": {
          "duration": 0.027979,
          "end_time": "2024-06-24T11:54:17.638944",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.610965",
          "status": "completed"
        },
        "tags": [],
        "id": "05c9ee85",
        "outputId": "4976d592-30e1-4efa-e785-3767290ea54e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2036.000000\n",
              "mean       15.694990\n",
              "std         5.185957\n",
              "min         2.000000\n",
              "25%        12.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "max        48.000000\n",
              "Name: len, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['len'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b23541e",
      "metadata": {
        "papermill": {
          "duration": 0.016518,
          "end_time": "2024-06-24T11:54:17.671838",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.655320",
          "status": "completed"
        },
        "tags": [],
        "id": "2b23541e"
      },
      "source": [
        "## Create Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6036c67",
      "metadata": {
        "papermill": {
          "duration": 0.016151,
          "end_time": "2024-06-24T11:54:17.704430",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.688279",
          "status": "completed"
        },
        "tags": [],
        "id": "c6036c67"
      },
      "source": [
        "### Create tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b82523",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:17.779198Z",
          "iopub.status.busy": "2024-06-24T11:54:17.778372Z",
          "iopub.status.idle": "2024-06-24T11:54:20.298040Z",
          "shell.execute_reply": "2024-06-24T11:54:20.297211Z"
        },
        "papermill": {
          "duration": 2.579275,
          "end_time": "2024-06-24T11:54:20.300349",
          "exception": false,
          "start_time": "2024-06-24T11:54:17.721074",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "693e54452f444da3b5284c75c2853e33",
            "75c2a39535a5443ba51869b53678c3d6",
            "16fe13e8a0724b899bbbdacfb6baf7a7",
            "a051d026a23048f1a24fb2194dd6ee62"
          ]
        },
        "id": "a7b82523",
        "outputId": "dff242ea-0954-437f-df13-8092faf40a5b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "693e54452f444da3b5284c75c2853e33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75c2a39535a5443ba51869b53678c3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16fe13e8a0724b899bbbdacfb6baf7a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a051d026a23048f1a24fb2194dd6ee62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a43f142",
      "metadata": {
        "papermill": {
          "duration": 0.017437,
          "end_time": "2024-06-24T11:54:20.335422",
          "exception": false,
          "start_time": "2024-06-24T11:54:20.317985",
          "status": "completed"
        },
        "tags": [],
        "id": "4a43f142"
      },
      "source": [
        "### Create TextDataset\n",
        "I created TextDataset based on Torch Dataset. This class takes DataFrame df and tokenizer as input.\n",
        "TextDataset has two main functions: init function (init object) and __getitem__ (function to sample batch data)\n",
        "- In the init function, I create a label column by converting the sentiment column to a number (positive --> 0, neutral --> 1, negative --> 2).\n",
        "- In the __getitem__  function:\n",
        "  - The input of this function is an index (torch Dataset auto input index when training, we don't need to do anything more).\n",
        "  - we get text input and label of this index row in DataFrame, convert text to input_ids and attention_mask with tokenizer.encode_plus(text, return_tensors='pt', padding='max_length', max_length=128).\n",
        "  - I set return_tensors = 'pt' to return torch tensor (instead of number or tf format). Setting padding to 'max_length' then tokenizer auto adds padding and max_length = 128 to cut text no longer than 128."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4020c557",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:20.371737Z",
          "iopub.status.busy": "2024-06-24T11:54:20.370938Z",
          "iopub.status.idle": "2024-06-24T11:54:20.405941Z",
          "shell.execute_reply": "2024-06-24T11:54:20.404852Z"
        },
        "papermill": {
          "duration": 0.055184,
          "end_time": "2024-06-24T11:54:20.407897",
          "exception": false,
          "start_time": "2024-06-24T11:54:20.352713",
          "status": "completed"
        },
        "tags": [],
        "id": "4020c557",
        "outputId": "51752f4d-5751-4ebf-88a3-dc2daf5bf54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentiment\n",
            "neutral     2724\n",
            "negative    2711\n",
            "positive    2709\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "1    2724\n",
            "2    2711\n",
            "0    2709\n",
            "Name: count, dtype: int64\n",
            "sentiment\n",
            "negative    686\n",
            "positive    680\n",
            "neutral     670\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "2    686\n",
            "0    680\n",
            "1    670\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.df = self.df.dropna(subset = ['sentence', 'sentiment'])\n",
        "        print(self.df['sentiment'].value_counts())\n",
        "        self.df['label'] = self.df['sentiment'].map(SENTIMENT_MAPPER)\n",
        "        print(self.df['label'].value_counts())\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.df.iloc[index]['sentence'])\n",
        "        label = self.df.iloc[index]['label']\n",
        "\n",
        "        # Tokenize the post and comment\n",
        "        input_ids = self.tokenizer.encode_plus(text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "        attention_mask = input_ids[\"attention_mask\"][:, :128].reshape(-1)\n",
        "        input_ids = input_ids[\"input_ids\"][:, :128].reshape(-1)\n",
        "\n",
        "        return (input_ids, attention_mask, label)\n",
        "\n",
        "SENTIMENT_MAPPER = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
        "\n",
        "# Load the data\n",
        "train_dataset = TextDataset(df_train, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TextDataset(df_test, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf34ade5",
      "metadata": {
        "papermill": {
          "duration": 0.017039,
          "end_time": "2024-06-24T11:54:20.442448",
          "exception": false,
          "start_time": "2024-06-24T11:54:20.425409",
          "status": "completed"
        },
        "tags": [],
        "id": "bf34ade5"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187f765c",
      "metadata": {
        "papermill": {
          "duration": 0.01683,
          "end_time": "2024-06-24T11:54:20.476582",
          "exception": false,
          "start_time": "2024-06-24T11:54:20.459752",
          "status": "completed"
        },
        "tags": [],
        "id": "187f765c"
      },
      "source": [
        "### Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce948f98",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:20.512557Z",
          "iopub.status.busy": "2024-06-24T11:54:20.511938Z",
          "iopub.status.idle": "2024-06-24T11:54:26.362529Z",
          "shell.execute_reply": "2024-06-24T11:54:26.361715Z"
        },
        "papermill": {
          "duration": 5.870949,
          "end_time": "2024-06-24T11:54:26.364767",
          "exception": false,
          "start_time": "2024-06-24T11:54:20.493818",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "5015e3dbc7dc4e4e847e0e99eecd6d87",
            "0372918a2d6b4eb3a0693a47b5b3d193"
          ]
        },
        "id": "ce948f98",
        "outputId": "b844702f-4978-4d8a-bb7e-df4beab7d6c9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5015e3dbc7dc4e4e847e0e99eecd6d87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0372918a2d6b4eb3a0693a47b5b3d193",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class MODEL(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MODEL, self).__init__()\n",
        "        self.model = AutoModel.from_pretrained('intfloat/multilingual-e5-base')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.linear_layer = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        hidden_states = self.model(input_ids, attention_mask).pooler_output\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        outpit = self.linear_layer(hidden_states)\n",
        "        return outpit\n",
        "\n",
        "# Initialize the model\n",
        "model = MODEL(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ba774a",
      "metadata": {
        "papermill": {
          "duration": 0.017465,
          "end_time": "2024-06-24T11:54:26.400314",
          "exception": false,
          "start_time": "2024-06-24T11:54:26.382849",
          "status": "completed"
        },
        "tags": [],
        "id": "b6ba774a"
      },
      "source": [
        "### Create optimizer\n",
        "- The first layers need lower learning rates, and the later ones need higher ones. So I divided layers into 4 groups:\n",
        "  - layers 0-->3 with learning rate = init_lr\n",
        "  - layers 4-->7 with learning rate = 1.5 * init_lr\n",
        "  - layers 8-->11 with learning_rate = 2 * init_lr\n",
        "  - linear or pooler with learning_rate = 3 * initial_lr.\n",
        "- With bias and LayerNorm, I do not use weight decay so I will set the weight decay of bias and LayerNorm to 0.\n",
        "- To customize learning_rate and weight_decay for each layer, push dictionary {'param': layer's params, 'lr': layer's learning rate, 'weight_decay': layer's weight_decay} to the optimized_parameters list. Then set optimizer = torch.optim.AdamW(optimized_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411b230d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:26.437027Z",
          "iopub.status.busy": "2024-06-24T11:54:26.436349Z",
          "iopub.status.idle": "2024-06-24T11:54:26.464570Z",
          "shell.execute_reply": "2024-06-24T11:54:26.463702Z"
        },
        "papermill": {
          "duration": 0.0488,
          "end_time": "2024-06-24T11:54:26.466546",
          "exception": false,
          "start_time": "2024-06-24T11:54:26.417746",
          "status": "completed"
        },
        "tags": [],
        "id": "411b230d"
      },
      "outputs": [],
      "source": [
        "optimized_parameters = []\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    lr = init_lr\n",
        "    weight_decay = 0.0 if any(nd in name for nd in no_decay) else 0.01\n",
        "\n",
        "    if name in ['linear_layer.weight', 'linear_layer.bias'] or 'pooler' in name or 'LinearTransformation' in name:\n",
        "        lr = init_lr * 3\n",
        "    elif 'layer.11' in name or 'layer.10' in name or 'layer.9' in name or 'layer.8' in name:\n",
        "        lr = init_lr * 2\n",
        "    elif 'layer.7' in name or 'layer.6' in name or 'layer.5' in name or 'layer.4' in name:\n",
        "        lr = init_lr * 1.5\n",
        "    else:\n",
        "        lr = init_lr\n",
        "\n",
        "    optimized_parameters.append({'params': param,\n",
        "                                     'weight_decay': weight_decay,\n",
        "                                     'lr': lr})\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimized_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c2931f",
      "metadata": {
        "papermill": {
          "duration": 0.017473,
          "end_time": "2024-06-24T11:54:26.501563",
          "exception": false,
          "start_time": "2024-06-24T11:54:26.484090",
          "status": "completed"
        },
        "tags": [],
        "id": "a1c2931f"
      },
      "source": [
        "### Create criterion and learning_rate scheduler\n",
        "I use torch.cuda.amp.GradScaler to enable 16 bit training (save memory and time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927d12c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:26.537947Z",
          "iopub.status.busy": "2024-06-24T11:54:26.537667Z",
          "iopub.status.idle": "2024-06-24T11:54:26.588942Z",
          "shell.execute_reply": "2024-06-24T11:54:26.587802Z"
        },
        "papermill": {
          "duration": 0.07165,
          "end_time": "2024-06-24T11:54:26.590852",
          "exception": false,
          "start_time": "2024-06-24T11:54:26.519202",
          "status": "completed"
        },
        "tags": [],
        "id": "927d12c5",
        "outputId": "99f5433d-5294-4769-8918-0a517bd40c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2036\n"
          ]
        }
      ],
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing = 0.2)\n",
        "total_steps = epochs * len(train_dataloader)\n",
        "print(total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=min(500, total_steps//10),\n",
        "                                            num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d547714",
      "metadata": {
        "papermill": {
          "duration": 0.017518,
          "end_time": "2024-06-24T11:54:26.626100",
          "exception": false,
          "start_time": "2024-06-24T11:54:26.608582",
          "status": "completed"
        },
        "tags": [],
        "id": "1d547714"
      },
      "source": [
        "## Training\n",
        "Just create training and eval loop normally. To enable 16 bit training:\n",
        "- use torch.cuda.amp.autocast to predict and calculate loss --> Pytorch will do forward and calculate loss in 16 bit (cut time and memory).\n",
        "- use scaler.scale(loss) to scale 16 bit loss back to 32 bit (because model 32 bit can't update with 16 bit loss backward).\n",
        "- use scaler.step(optimizer) and scaler.update() to ensure optimizer.step do correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9a38b4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T11:54:26.662860Z",
          "iopub.status.busy": "2024-06-24T11:54:26.662595Z",
          "iopub.status.idle": "2024-06-24T12:03:54.517170Z",
          "shell.execute_reply": "2024-06-24T12:03:54.515922Z"
        },
        "papermill": {
          "duration": 567.875428,
          "end_time": "2024-06-24T12:03:54.519313",
          "exception": false,
          "start_time": "2024-06-24T11:54:26.643885",
          "status": "completed"
        },
        "tags": [],
        "id": "e9a38b4a",
        "outputId": "3864137d-5226-4633-dc72-47b3602e150c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(56.2500) tensor(1.0808, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(40.5637) tensor(1.0521, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(56.0644) tensor(0.7898, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(63.3692) tensor(0.7432, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(67.5995) tensor(0.7091, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(70.5179) tensor(0.7626, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(72.0723) tensor(0.6368, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(73.7714) tensor(0.6966, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(74.7039) tensor(0.7510, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(75.8731) tensor(0.7449, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(76.5469) tensor(0.6283, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(87.5000) tensor(0.5952, device='cuda:0')\n",
            "100 tensor(86.2624) tensor(0.5576, device='cuda:0')\n",
            "Epoch 1, train_acc: 0.7660854458808899, test_acc: 0.8610019683837891, f1: 0.8599264396013894, epoch_time: 0:02:19.202842\n",
            "0 tensor(87.5000) tensor(0.6165, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(83.3333) tensor(0.6280, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(84.9010) tensor(0.5554, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(85.7616) tensor(0.8180, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(85.7276) tensor(0.6713, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(86.1554) tensor(0.5853, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(86.4203) tensor(0.5824, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(86.3070) tensor(0.6127, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(86.2531) tensor(0.5276, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(86.1696) tensor(0.7299, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(86.2400) tensor(0.6597, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(93.7500) tensor(0.5719, device='cuda:0')\n",
            "100 tensor(87.6856) tensor(0.5996, device='cuda:0')\n",
            "Epoch 2, train_acc: 0.8622298836708069, test_acc: 0.8762279152870178, f1: 0.8760566206707678, epoch_time: 0:02:25.805308\n",
            "0 tensor(81.2500) tensor(0.7212, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(88.8480) tensor(0.5925, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(87.6856) tensor(0.6019, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(88.2450) tensor(0.5777, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(88.7127) tensor(0.5482, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(88.9442) tensor(0.6732, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(89.2857) tensor(0.5475, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(89.4765) tensor(0.5449, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(89.6197) tensor(0.6736, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(89.5649) tensor(0.6500, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(89.7330) tensor(0.6836, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(100.) tensor(0.5258, device='cuda:0')\n",
            "100 tensor(88.6757) tensor(0.6610, device='cuda:0')\n",
            "Epoch 3, train_acc: 0.896733820438385, test_acc: 0.8840864300727844, f1: 0.8838095437715042, epoch_time: 0:02:19.498481\n",
            "0 tensor(87.5000) tensor(0.5962, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(91.5441) tensor(0.5374, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(93.0074) tensor(0.5259, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(93.4603) tensor(0.6040, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(93.0348) tensor(0.6227, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(92.8785) tensor(0.5241, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(92.8156) tensor(0.5493, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(92.4145) tensor(0.6220, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(92.5187) tensor(0.5854, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(92.6136) tensor(0.5799, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(92.6647) tensor(0.5995, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(100.) tensor(0.5072, device='cuda:0')\n",
            "100 tensor(89.7277) tensor(0.6711, device='cuda:0')\n",
            "Epoch 4, train_acc: 0.9269400835037231, test_acc: 0.8953831195831299, f1: 0.8948048705360745, epoch_time: 0:02:22.872185\n",
            "total training time:  0:09:27.837823\n"
          ]
        }
      ],
      "source": [
        "max_acc = 0\n",
        "max_f1 = 0\n",
        "\n",
        "start_train = datetime.now()\n",
        "model = model.cuda()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_acc = 0\n",
        "    len_train = 0\n",
        "    model.train()\n",
        "    start_epoch = datetime.now()\n",
        "\n",
        "    for batch_idx, (input_ids, attention_mask, label) in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 3).float()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                predict = model(input_ids, attention_mask)\n",
        "                loss = criterion(predict, label)\n",
        "            scaler.scale(loss).backward() #loss.backward()\n",
        "            scaler.step(optimizer) #optimizer.step()\n",
        "\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                    predict = predict.argmax(-1)\n",
        "                    train_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_train += len(label)\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(batch_idx, train_acc / len_train * 100, loss)\n",
        "\n",
        "            #break\n",
        "            #torch.cuda.empty_cache()\n",
        "\n",
        "    train_acc = train_acc / len_train\n",
        "\n",
        "    test_acc = 0\n",
        "    len_test = 0\n",
        "    model.eval()\n",
        "\n",
        "    test_labels = []\n",
        "    test_predicts = []\n",
        "\n",
        "    for batch_idx, (input_ids, attention_mask, label) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 3).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predict = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict, label)\n",
        "\n",
        "                    predict = predict.argmax(-1)\n",
        "                    test_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label)\n",
        "\n",
        "                    test_labels += label.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts += predict.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc / len_test * 100, loss)\n",
        "\n",
        "    test_acc = test_acc / len_test\n",
        "\n",
        "    f1 = f1_score(test_predicts, test_labels, average = 'macro')\n",
        "\n",
        "    if test_acc > max_acc:\n",
        "        max_acc = test_acc\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"sentiment_max_acc.pt\")\n",
        "\n",
        "    if f1 > max_f1:\n",
        "        max_f1 = f1\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"sentiment_max_f1.pt\")\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch {epoch + 1}, train_acc: {train_acc}, test_acc: {test_acc}, f1: {f1}, epoch_time: {datetime.now() - start_epoch}')\n",
        "\n",
        "print('total training time: ', datetime.now() - start_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c75a22",
      "metadata": {
        "papermill": {
          "duration": 0.022043,
          "end_time": "2024-06-24T12:03:54.563637",
          "exception": false,
          "start_time": "2024-06-24T12:03:54.541594",
          "status": "completed"
        },
        "tags": [],
        "id": "64c75a22"
      },
      "source": [
        "## Eval\n",
        "You can see good results with accuracy of 89.54%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6751e479",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:03:54.608802Z",
          "iopub.status.busy": "2024-06-24T12:03:54.608487Z",
          "iopub.status.idle": "2024-06-24T12:04:04.329890Z",
          "shell.execute_reply": "2024-06-24T12:04:04.328826Z"
        },
        "papermill": {
          "duration": 9.746577,
          "end_time": "2024-06-24T12:04:04.332031",
          "exception": false,
          "start_time": "2024-06-24T12:03:54.585454",
          "status": "completed"
        },
        "tags": [],
        "id": "6751e479",
        "outputId": "4c303f24-bc86-4652-a7f6-e750340825ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(100.) tensor(0.5072, device='cuda:0')\n",
            "100 tensor(89.7277) tensor(0.6711, device='cuda:0')\n",
            "tensor(0.8954) 0.8948048705360745\n"
          ]
        }
      ],
      "source": [
        "test_acc = 0\n",
        "len_test = 0\n",
        "\n",
        "model.load_state_dict(torch.load(\"sentiment_max_f1.pt\")['model'])\n",
        "test_labels = []\n",
        "test_predicts = []\n",
        "\n",
        "for batch_idx, (input_ids, attention_mask, label) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 3).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predict = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict, label)\n",
        "\n",
        "                    predict = predict.argmax(-1)\n",
        "                    test_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label)\n",
        "\n",
        "                    test_labels += label.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts += predict.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc / len_test * 100, loss)\n",
        "\n",
        "test_acc = test_acc / len_test\n",
        "f1 = f1_score(test_predicts, test_labels, average = 'macro')\n",
        "\n",
        "print(test_acc, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a7c552",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:04.379201Z",
          "iopub.status.busy": "2024-06-24T12:04:04.378906Z",
          "iopub.status.idle": "2024-06-24T12:04:04.393589Z",
          "shell.execute_reply": "2024-06-24T12:04:04.392527Z"
        },
        "papermill": {
          "duration": 0.040494,
          "end_time": "2024-06-24T12:04:04.395672",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.355178",
          "status": "completed"
        },
        "tags": [],
        "id": "95a7c552",
        "outputId": "657dff2c-f412-4e18-ee6a-d83ec94b5743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8446    0.8794    0.8617       680\n",
            "           1     0.8558    0.8239    0.8395       670\n",
            "           2     0.9854    0.9810    0.9832       686\n",
            "\n",
            "    accuracy                         0.8954      2036\n",
            "   macro avg     0.8953    0.8948    0.8948      2036\n",
            "weighted avg     0.8957    0.8954    0.8953      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## label smoothing 0.2\n",
        "print(sklearn.metrics.classification_report(test_labels, test_predicts, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dada8891",
      "metadata": {
        "papermill": {
          "duration": 0.022423,
          "end_time": "2024-06-24T12:04:04.441227",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.418804",
          "status": "completed"
        },
        "tags": [],
        "id": "dada8891"
      },
      "source": [
        "# topic\n",
        "Do same thing like sentiment training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afdc8fe5",
      "metadata": {
        "papermill": {
          "duration": 0.02265,
          "end_time": "2024-06-24T12:04:04.486243",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.463593",
          "status": "completed"
        },
        "tags": [],
        "id": "afdc8fe5"
      },
      "source": [
        "## Review data\n",
        "Dataset is balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df55d91",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:04.532382Z",
          "iopub.status.busy": "2024-06-24T12:04:04.532119Z",
          "iopub.status.idle": "2024-06-24T12:04:04.540303Z",
          "shell.execute_reply": "2024-06-24T12:04:04.539521Z"
        },
        "papermill": {
          "duration": 0.033537,
          "end_time": "2024-06-24T12:04:04.542269",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.508732",
          "status": "completed"
        },
        "tags": [],
        "id": "6df55d91",
        "outputId": "939ebde3-8334-4128-f793-4e41bde672bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "topic\n",
              "others        2059\n",
              "curriculum    2040\n",
              "lecturer      2026\n",
              "facility      2019\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.topic.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cb7f7a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:04.588986Z",
          "iopub.status.busy": "2024-06-24T12:04:04.588744Z",
          "iopub.status.idle": "2024-06-24T12:04:04.595678Z",
          "shell.execute_reply": "2024-06-24T12:04:04.594855Z"
        },
        "papermill": {
          "duration": 0.032483,
          "end_time": "2024-06-24T12:04:04.597828",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.565345",
          "status": "completed"
        },
        "tags": [],
        "id": "c5cb7f7a",
        "outputId": "302cebaf-c22e-4ccf-a627-592575c26c82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "topic\n",
              "facility      526\n",
              "lecturer      515\n",
              "curriculum    507\n",
              "others        488\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.topic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe062b54",
      "metadata": {
        "papermill": {
          "duration": 0.022278,
          "end_time": "2024-06-24T12:04:04.642524",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.620246",
          "status": "completed"
        },
        "tags": [],
        "id": "fe062b54"
      },
      "source": [
        "## Create TextDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14476789",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:04.688754Z",
          "iopub.status.busy": "2024-06-24T12:04:04.688484Z",
          "iopub.status.idle": "2024-06-24T12:04:04.712434Z",
          "shell.execute_reply": "2024-06-24T12:04:04.711271Z"
        },
        "papermill": {
          "duration": 0.049341,
          "end_time": "2024-06-24T12:04:04.714318",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.664977",
          "status": "completed"
        },
        "tags": [],
        "id": "14476789",
        "outputId": "8980082e-5fc9-43f6-861a-791d437659d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topic\n",
            "others        2059\n",
            "curriculum    2040\n",
            "lecturer      2026\n",
            "facility      2019\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "3    2059\n",
            "2    2040\n",
            "1    2026\n",
            "0    2019\n",
            "Name: count, dtype: int64\n",
            "topic\n",
            "facility      526\n",
            "lecturer      515\n",
            "curriculum    507\n",
            "others        488\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    526\n",
            "1    515\n",
            "2    507\n",
            "3    488\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.df = self.df.dropna(subset = ['sentence', 'topic'])\n",
        "        print(self.df['topic'].value_counts())\n",
        "        self.df['label'] = self.df['topic'].map(TOPIC_MAPPER)\n",
        "        print(self.df['label'].value_counts())\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.df.iloc[index]['sentence'])\n",
        "        label = self.df.iloc[index]['label']\n",
        "\n",
        "        # Tokenize the post and comment\n",
        "        input_ids = self.tokenizer.encode_plus(text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "        attention_mask = input_ids[\"attention_mask\"][:, :128].reshape(-1)\n",
        "        input_ids = input_ids[\"input_ids\"][:, :128].reshape(-1)\n",
        "\n",
        "        return (input_ids, attention_mask, label)\n",
        "\n",
        "TOPIC_MAPPER = {'facility': 0,\n",
        "               'lecturer': 1,\n",
        "               'curriculum': 2,\n",
        "               'others': 3}\n",
        "\n",
        "# Load the data\n",
        "train_dataset = TextDataset(df_train, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TextDataset(df_test, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0972de15",
      "metadata": {
        "papermill": {
          "duration": 0.022811,
          "end_time": "2024-06-24T12:04:04.759858",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.737047",
          "status": "completed"
        },
        "tags": [],
        "id": "0972de15"
      },
      "source": [
        "## Create model, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd22410",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:04.806156Z",
          "iopub.status.busy": "2024-06-24T12:04:04.805871Z",
          "iopub.status.idle": "2024-06-24T12:04:05.460957Z",
          "shell.execute_reply": "2024-06-24T12:04:05.460147Z"
        },
        "papermill": {
          "duration": 0.68085,
          "end_time": "2024-06-24T12:04:05.463272",
          "exception": false,
          "start_time": "2024-06-24T12:04:04.782422",
          "status": "completed"
        },
        "tags": [],
        "id": "afd22410"
      },
      "outputs": [],
      "source": [
        "model = MODEL(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7c7de1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:05.511147Z",
          "iopub.status.busy": "2024-06-24T12:04:05.510856Z",
          "iopub.status.idle": "2024-06-24T12:04:05.539011Z",
          "shell.execute_reply": "2024-06-24T12:04:05.538380Z"
        },
        "papermill": {
          "duration": 0.053671,
          "end_time": "2024-06-24T12:04:05.540755",
          "exception": false,
          "start_time": "2024-06-24T12:04:05.487084",
          "status": "completed"
        },
        "tags": [],
        "id": "9a7c7de1"
      },
      "outputs": [],
      "source": [
        "optimized_parameters = []\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    lr = init_lr\n",
        "    weight_decay = 0.0 if any(nd in name for nd in no_decay) else 0.01\n",
        "\n",
        "    if name in ['linear_layer.weight', 'linear_layer.bias'] or 'pooler' in name or 'LinearTransformation' in name:\n",
        "        lr = init_lr * 3\n",
        "    elif 'layer.11' in name or 'layer.10' in name or 'layer.9' in name or 'layer.8' in name:\n",
        "        lr = init_lr * 2\n",
        "    elif 'layer.7' in name or 'layer.6' in name or 'layer.5' in name or 'layer.4' in name:\n",
        "        lr = init_lr * 1,5\n",
        "    else:\n",
        "        lr = init_lr\n",
        "\n",
        "    optimized_parameters.append({'params': param,\n",
        "                                     'weight_decay': weight_decay,\n",
        "                                     'lr': lr})\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimized_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdeef45e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:05.586994Z",
          "iopub.status.busy": "2024-06-24T12:04:05.586693Z",
          "iopub.status.idle": "2024-06-24T12:04:05.594603Z",
          "shell.execute_reply": "2024-06-24T12:04:05.593731Z"
        },
        "papermill": {
          "duration": 0.033111,
          "end_time": "2024-06-24T12:04:05.596397",
          "exception": false,
          "start_time": "2024-06-24T12:04:05.563286",
          "status": "completed"
        },
        "tags": [],
        "id": "bdeef45e",
        "outputId": "63d05637-ec90-4ab0-88db-0731226943aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2036\n"
          ]
        }
      ],
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing = 0.2)\n",
        "total_steps = epochs * len(train_dataloader)\n",
        "print(total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=min(500, total_steps//10),\n",
        "                                            num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60c21fc",
      "metadata": {
        "papermill": {
          "duration": 0.022475,
          "end_time": "2024-06-24T12:04:05.641702",
          "exception": false,
          "start_time": "2024-06-24T12:04:05.619227",
          "status": "completed"
        },
        "tags": [],
        "id": "d60c21fc"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71627844",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:04:05.688612Z",
          "iopub.status.busy": "2024-06-24T12:04:05.687981Z",
          "iopub.status.idle": "2024-06-24T12:13:19.602031Z",
          "shell.execute_reply": "2024-06-24T12:13:19.601066Z"
        },
        "papermill": {
          "duration": 553.940131,
          "end_time": "2024-06-24T12:13:19.604372",
          "exception": false,
          "start_time": "2024-06-24T12:04:05.664241",
          "status": "completed"
        },
        "tags": [],
        "id": "71627844",
        "outputId": "dde020b2-b4fb-41bd-faeb-ea3a057cb6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(18.7500) tensor(1.4178, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(35.9069) tensor(1.3356, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(57.3639) tensor(0.7345, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(68.3361) tensor(0.7572, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(74.2226) tensor(0.6342, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(77.8635) tensor(0.6891, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(80.5233) tensor(0.7094, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(82.3718) tensor(0.7050, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(83.9931) tensor(0.6653, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(85.3104) tensor(0.7292, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(86.0654) tensor(0.5994, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(81.2500) tensor(0.9483, device='cuda:0')\n",
            "100 tensor(94.6163) tensor(0.6998, device='cuda:0')\n",
            "Epoch 1, train_acc: 0.8612475395202637, test_acc: 0.9440078735351562, f1: 0.944613285653287, epoch_time: 0:02:18.256397\n",
            "0 tensor(100.) tensor(0.6107, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(96.4461) tensor(0.6016, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(96.6584) tensor(0.6643, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(96.5646) tensor(0.6022, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(96.3930) tensor(0.5955, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(96.1404) tensor(0.6983, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(96.2417) tensor(0.5922, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(96.3141) tensor(0.5929, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(96.3996) tensor(0.6217, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(96.3553) tensor(0.6676, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(96.3822) tensor(0.6361, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(81.2500) tensor(0.8144, device='cuda:0')\n",
            "100 tensor(96.5347) tensor(0.6849, device='cuda:0')\n",
            "Epoch 2, train_acc: 0.9641453623771667, test_acc: 0.9646365642547607, f1: 0.9648247393940987, epoch_time: 0:02:26.220589\n",
            "0 tensor(87.5000) tensor(0.7480, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(97.3039) tensor(0.6018, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(97.5247) tensor(0.5942, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(97.5993) tensor(0.5930, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(97.6057) tensor(0.5967, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(97.7092) tensor(0.6251, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(97.6952) tensor(0.6352, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(97.7742) tensor(0.7125, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(97.8024) tensor(0.5959, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(97.8243) tensor(0.5932, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(97.8418) tensor(0.5965, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(81.2500) tensor(0.7531, device='cuda:0')\n",
            "100 tensor(96.2253) tensor(0.5982, device='cuda:0')\n",
            "Epoch 3, train_acc: 0.978266179561615, test_acc: 0.9626718759536743, f1: 0.9628803583645578, epoch_time: 0:02:14.625313\n",
            "0 tensor(100.) tensor(0.6056, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "50 tensor(98.8971) tensor(0.5936, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "100 tensor(98.7624) tensor(0.6046, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "150 tensor(98.8411) tensor(0.6133, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "200 tensor(98.7562) tensor(0.5942, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "250 tensor(98.8546) tensor(0.6968, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "300 tensor(98.8580) tensor(0.6236, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "350 tensor(98.9316) tensor(0.5981, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "400 tensor(98.9090) tensor(0.5907, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "450 tensor(98.9052) tensor(0.6270, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "500 tensor(98.9022) tensor(0.5937, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "0 tensor(81.2500) tensor(0.8474, device='cuda:0')\n",
            "100 tensor(95.9158) tensor(0.5944, device='cuda:0')\n",
            "Epoch 4, train_acc: 0.9888261556625366, test_acc: 0.9597249627113342, f1: 0.9601426499035678, epoch_time: 0:02:14.491699\n",
            "total training time:  0:09:13.897818\n"
          ]
        }
      ],
      "source": [
        "max_acc = 0\n",
        "max_f1 = 0\n",
        "\n",
        "start_train = datetime.now()\n",
        "model = model.cuda()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_acc = 0\n",
        "    len_train = 0\n",
        "    model.train()\n",
        "    start_epoch = datetime.now()\n",
        "\n",
        "    for batch_idx, (input_ids, attention_mask, label) in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 4).float()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                predict = model(input_ids, attention_mask)\n",
        "                loss = criterion(predict, label)\n",
        "            scaler.scale(loss).backward() #loss.backward()\n",
        "            scaler.step(optimizer) #optimizer.step()\n",
        "\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                    predict = predict.argmax(-1)\n",
        "                    train_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_train += len(label)\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(batch_idx, train_acc / len_train * 100, loss)\n",
        "\n",
        "            #break\n",
        "            #torch.cuda.empty_cache()\n",
        "\n",
        "    train_acc = train_acc / len_train\n",
        "\n",
        "    test_acc = 0\n",
        "    len_test = 0\n",
        "    model.eval()\n",
        "\n",
        "    test_labels = []\n",
        "    test_predicts = []\n",
        "\n",
        "    for batch_idx, (input_ids, attention_mask, label) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 4).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predict = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict, label)\n",
        "\n",
        "                    predict = predict.argmax(-1)\n",
        "                    test_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label)\n",
        "\n",
        "                    test_labels += label.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts += predict.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc / len_test * 100, loss)\n",
        "\n",
        "    test_acc = test_acc / len_test\n",
        "\n",
        "    f1 = f1_score(test_predicts, test_labels, average = 'macro')\n",
        "\n",
        "    if test_acc > max_acc:\n",
        "        max_acc = test_acc\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"topic_max_acc.pt\")\n",
        "\n",
        "    if f1 > max_f1:\n",
        "        max_f1 = f1\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"topic_max_f1.pt\")\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch {epoch + 1}, train_acc: {train_acc}, test_acc: {test_acc}, f1: {f1}, epoch_time: {datetime.now() - start_epoch}')\n",
        "\n",
        "print('total training time: ', datetime.now() - start_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56359de6",
      "metadata": {
        "papermill": {
          "duration": 0.026918,
          "end_time": "2024-06-24T12:13:19.658715",
          "exception": false,
          "start_time": "2024-06-24T12:13:19.631797",
          "status": "completed"
        },
        "tags": [],
        "id": "56359de6"
      },
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50440df2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:19.713738Z",
          "iopub.status.busy": "2024-06-24T12:13:19.713377Z",
          "iopub.status.idle": "2024-06-24T12:13:29.334837Z",
          "shell.execute_reply": "2024-06-24T12:13:29.333777Z"
        },
        "papermill": {
          "duration": 9.651519,
          "end_time": "2024-06-24T12:13:29.337042",
          "exception": false,
          "start_time": "2024-06-24T12:13:19.685523",
          "status": "completed"
        },
        "tags": [],
        "id": "50440df2",
        "outputId": "08bba066-b741-44c4-f079-dc8be2a5dfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(81.2500) tensor(0.8144, device='cuda:0')\n",
            "100 tensor(96.5347) tensor(0.6849, device='cuda:0')\n",
            "tensor(0.9646) 0.9648247393940987\n"
          ]
        }
      ],
      "source": [
        "test_acc = 0\n",
        "len_test = 0\n",
        "\n",
        "model.load_state_dict(torch.load(\"topic_max_f1.pt\")['model'])\n",
        "test_labels = []\n",
        "test_predicts = []\n",
        "\n",
        "for batch_idx, (input_ids, attention_mask, label) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 4).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predict = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict, label)\n",
        "\n",
        "                    predict = predict.argmax(-1)\n",
        "                    test_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label)\n",
        "\n",
        "                    test_labels += label.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts += predict.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc / len_test * 100, loss)\n",
        "\n",
        "test_acc = test_acc / len_test\n",
        "f1 = f1_score(test_predicts, test_labels, average = 'macro')\n",
        "\n",
        "print(test_acc, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f32a835",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:29.393293Z",
          "iopub.status.busy": "2024-06-24T12:13:29.392987Z",
          "iopub.status.idle": "2024-06-24T12:13:29.407010Z",
          "shell.execute_reply": "2024-06-24T12:13:29.405991Z"
        },
        "papermill": {
          "duration": 0.044205,
          "end_time": "2024-06-24T12:13:29.408906",
          "exception": false,
          "start_time": "2024-06-24T12:13:29.364701",
          "status": "completed"
        },
        "tags": [],
        "id": "7f32a835",
        "outputId": "3a8b565d-1016-4368-c182-2ef1e240b01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9497    0.9696    0.9595       526\n",
            "           1     0.9710    0.9748    0.9729       515\n",
            "           2     0.9452    0.9191    0.9320       507\n",
            "           3     0.9939    0.9959    0.9949       488\n",
            "\n",
            "    accuracy                         0.9646      2036\n",
            "   macro avg     0.9650    0.9648    0.9648      2036\n",
            "weighted avg     0.9646    0.9646    0.9645      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## label smoothing 0.2\n",
        "print(sklearn.metrics.classification_report(test_labels, test_predicts, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935b209e",
      "metadata": {
        "papermill": {
          "duration": 0.026845,
          "end_time": "2024-06-24T12:13:29.462899",
          "exception": false,
          "start_time": "2024-06-24T12:13:29.436054",
          "status": "completed"
        },
        "tags": [],
        "id": "935b209e"
      },
      "source": [
        "# Multitask\n",
        "Training model to predict both sentiment and topic. We can see that performance is still good as training separately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00dfcc8",
      "metadata": {
        "papermill": {
          "duration": 0.026833,
          "end_time": "2024-06-24T12:13:29.517113",
          "exception": false,
          "start_time": "2024-06-24T12:13:29.490280",
          "status": "completed"
        },
        "tags": [],
        "id": "c00dfcc8"
      },
      "source": [
        "## Create TextDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e517bcee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:29.572626Z",
          "iopub.status.busy": "2024-06-24T12:13:29.572325Z",
          "iopub.status.idle": "2024-06-24T12:13:29.595771Z",
          "shell.execute_reply": "2024-06-24T12:13:29.594854Z"
        },
        "papermill": {
          "duration": 0.053359,
          "end_time": "2024-06-24T12:13:29.597596",
          "exception": false,
          "start_time": "2024-06-24T12:13:29.544237",
          "status": "completed"
        },
        "tags": [],
        "id": "e517bcee"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.df = self.df.dropna(subset = ['sentence', 'sentiment', 'topic'])\n",
        "        self.df['label_sentiment'] = self.df['sentiment'].map(SENTIMENT_MAPPER)\n",
        "        self.df['label_topic'] = self.df['topic'].map(TOPIC_MAPPER)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.df.iloc[index]['sentence'])\n",
        "        label_sentiment = self.df.iloc[index]['label_sentiment']\n",
        "        label_topic = self.df.iloc[index]['label_topic']\n",
        "\n",
        "        # Tokenize the post and comment\n",
        "        input_ids = self.tokenizer.encode_plus(text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "        attention_mask = input_ids[\"attention_mask\"][:, :128].reshape(-1)\n",
        "        input_ids = input_ids[\"input_ids\"][:, :128].reshape(-1)\n",
        "\n",
        "        return (input_ids, attention_mask, label_sentiment, label_topic)\n",
        "\n",
        "SENTIMENT_MAPPER = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
        "TOPIC_MAPPER = {'facility': 0,\n",
        "               'lecturer': 1,\n",
        "               'curriculum': 2,\n",
        "               'others': 3}\n",
        "\n",
        "# Load the data\n",
        "train_dataset = TextDataset(df_train, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TextDataset(df_test, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcd2a38",
      "metadata": {
        "papermill": {
          "duration": 0.027031,
          "end_time": "2024-06-24T12:13:29.651878",
          "exception": false,
          "start_time": "2024-06-24T12:13:29.624847",
          "status": "completed"
        },
        "tags": [],
        "id": "5bcd2a38"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1379d2a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:29.707160Z",
          "iopub.status.busy": "2024-06-24T12:13:29.706893Z",
          "iopub.status.idle": "2024-06-24T12:13:30.331471Z",
          "shell.execute_reply": "2024-06-24T12:13:30.330430Z"
        },
        "papermill": {
          "duration": 0.654925,
          "end_time": "2024-06-24T12:13:30.333955",
          "exception": false,
          "start_time": "2024-06-24T12:13:29.679030",
          "status": "completed"
        },
        "tags": [],
        "id": "e1379d2a"
      },
      "outputs": [],
      "source": [
        "class MODEL(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MODEL, self).__init__()\n",
        "        self.model = AutoModel.from_pretrained('intfloat/multilingual-e5-base')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.sentiment = nn.Linear(768, 3)\n",
        "        self.topic = nn.Linear(768, 4)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        hidden_states = self.model(input_ids, attention_mask).pooler_output\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        sentiment = self.sentiment(hidden_states)\n",
        "        topic = self.topic(hidden_states)\n",
        "        return sentiment, topic\n",
        "\n",
        "# Initialize the model\n",
        "model = MODEL()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d0b792",
      "metadata": {
        "papermill": {
          "duration": 0.027248,
          "end_time": "2024-06-24T12:13:30.389296",
          "exception": false,
          "start_time": "2024-06-24T12:13:30.362048",
          "status": "completed"
        },
        "tags": [],
        "id": "19d0b792"
      },
      "source": [
        "## Create optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee35b1bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:30.444656Z",
          "iopub.status.busy": "2024-06-24T12:13:30.444312Z",
          "iopub.status.idle": "2024-06-24T12:13:30.472320Z",
          "shell.execute_reply": "2024-06-24T12:13:30.471497Z"
        },
        "papermill": {
          "duration": 0.057574,
          "end_time": "2024-06-24T12:13:30.474147",
          "exception": false,
          "start_time": "2024-06-24T12:13:30.416573",
          "status": "completed"
        },
        "tags": [],
        "id": "ee35b1bf"
      },
      "outputs": [],
      "source": [
        "optimized_parameters = []\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    lr = init_lr\n",
        "    weight_decay = 0.0 if any(nd in name for nd in no_decay) else 0.01\n",
        "\n",
        "    if name in ['sentiment.weight', 'sentiment.bias', 'topic.weight', 'topic.bias'] or 'pooler' in name or 'LinearTransformation' in name:\n",
        "        lr = init_lr * 3\n",
        "    elif 'layer.11' in name or 'layer.10' in name or 'layer.9' in name or 'layer.8' in name:\n",
        "        lr = init_lr * 2\n",
        "    elif 'layer.7' in name or 'layer.6' in name or 'layer.5' in name or 'layer.4' in name:\n",
        "        lr = init_lr * 1.5\n",
        "    else:\n",
        "        lr = init_lr\n",
        "\n",
        "    optimized_parameters.append({'params': param,\n",
        "                                     'weight_decay': weight_decay,\n",
        "                                     'lr': lr})\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimized_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9ba05e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:30.529539Z",
          "iopub.status.busy": "2024-06-24T12:13:30.529262Z",
          "iopub.status.idle": "2024-06-24T12:13:30.537481Z",
          "shell.execute_reply": "2024-06-24T12:13:30.536585Z"
        },
        "papermill": {
          "duration": 0.038105,
          "end_time": "2024-06-24T12:13:30.539526",
          "exception": false,
          "start_time": "2024-06-24T12:13:30.501421",
          "status": "completed"
        },
        "tags": [],
        "id": "eb9ba05e",
        "outputId": "6d8d8692-4fde-4c5b-b34b-02d7a131779f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2036\n"
          ]
        }
      ],
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing = 0.2)\n",
        "total_steps = epochs * len(train_dataloader)\n",
        "print(total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=min(500, total_steps//10),\n",
        "                                            num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f525f8e",
      "metadata": {
        "papermill": {
          "duration": 0.02699,
          "end_time": "2024-06-24T12:13:30.593844",
          "exception": false,
          "start_time": "2024-06-24T12:13:30.566854",
          "status": "completed"
        },
        "tags": [],
        "id": "7f525f8e"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1ecaf0a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:13:30.649433Z",
          "iopub.status.busy": "2024-06-24T12:13:30.649191Z",
          "iopub.status.idle": "2024-06-24T12:23:41.349892Z",
          "shell.execute_reply": "2024-06-24T12:23:41.348536Z"
        },
        "papermill": {
          "duration": 610.762891,
          "end_time": "2024-06-24T12:23:41.383880",
          "exception": false,
          "start_time": "2024-06-24T12:13:30.620989",
          "status": "completed"
        },
        "tags": [],
        "id": "b1ecaf0a",
        "outputId": "7de22c5c-0e7e-4ec7-e855-43ecff3c7ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(50.) tensor(18.7500) tensor(2.4943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "50 tensor(42.2794) tensor(29.9020) tensor(2.4250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "100 tensor(55.6312) tensor(48.8861) tensor(1.7111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "150 tensor(62.1689) tensor(63.1209) tensor(1.5175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "200 tensor(66.1070) tensor(70.5224) tensor(1.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "250 tensor(68.3267) tensor(75.0249) tensor(1.4567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "300 tensor(70.6395) tensor(78.1561) tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "350 tensor(71.9551) tensor(80.0570) tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "400 tensor(73.4570) tensor(81.8111) tensor(1.5250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "450 tensor(74.4041) tensor(83.1901) tensor(1.2635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500 tensor(75.2745) tensor(84.2565) tensor(1.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "0 tensor(100.) tensor(81.2500) tensor(1.4621, device='cuda:0')\n",
            "100 tensor(86.3243) tensor(95.9158) tensor(1.2634, device='cuda:0')\n",
            "Epoch 1, train_acc_sentiment: 0.7540520429611206, train_acc_topic: 0.8444253206253052, test_acc_sentiment: 0.8590373396873474, f1_sentiment: 0.8587439946675551, test_acc_topic: 0.9548133611679077, f1_topic: 0.9554886046781463, epoch_time: 0:02:23.213149\n",
            "0 tensor(81.2500) tensor(100.) tensor(1.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "50 tensor(86.7647) tensor(95.8333) tensor(1.5082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "100 tensor(87.1906) tensor(96.1015) tensor(1.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "150 tensor(86.5894) tensor(95.8609) tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "200 tensor(86.9092) tensor(95.7711) tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "250 tensor(86.7530) tensor(95.9412) tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "300 tensor(86.5656) tensor(96.1379) tensor(1.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "350 tensor(86.3070) tensor(96.0648) tensor(1.2857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "400 tensor(86.2687) tensor(96.0567) tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "450 tensor(86.2251) tensor(96.1613) tensor(1.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500 tensor(86.3398) tensor(96.2824) tensor(1.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "0 tensor(93.7500) tensor(81.2500) tensor(1.3090, device='cuda:0')\n",
            "100 tensor(87.7475) tensor(96.1015) tensor(1.2254, device='cuda:0')\n",
            "Epoch 2, train_acc_sentiment: 0.8643172979354858, train_acc_topic: 0.9624263048171997, test_acc_sentiment: 0.8762279152870178, f1_sentiment: 0.8753047195336144, test_acc_topic: 0.958742618560791, f1_topic: 0.9591198787823239, epoch_time: 0:02:30.945116\n",
            "0 tensor(81.2500) tensor(100.) tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "50 tensor(88.3578) tensor(97.9167) tensor(1.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "100 tensor(87.4381) tensor(98.0198) tensor(1.2004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "150 tensor(88.0795) tensor(97.9305) tensor(1.1607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "200 tensor(88.3085) tensor(97.9478) tensor(1.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "250 tensor(88.5458) tensor(97.8088) tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "300 tensor(88.7666) tensor(97.7782) tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "350 tensor(89.0848) tensor(97.7564) tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "400 tensor(89.1365) tensor(97.8024) tensor(1.4598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "450 tensor(89.4678) tensor(97.8659) tensor(1.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500 tensor(89.2465) tensor(97.9291) tensor(1.2638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "0 tensor(100.) tensor(81.2500) tensor(1.3148, device='cuda:0')\n",
            "100 tensor(89.1089) tensor(96.3490) tensor(1.1832, device='cuda:0')\n",
            "Epoch 3, train_acc_sentiment: 0.892436146736145, train_acc_topic: 0.9794940948486328, test_acc_sentiment: 0.8845776319503784, f1_sentiment: 0.8828815080506929, test_acc_topic: 0.9626718759536743, f1_topic: 0.9629965726402389, epoch_time: 0:02:34.216379\n",
            "0 tensor(93.7500) tensor(100.) tensor(1.1642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "50 tensor(91.7892) tensor(98.8971) tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "100 tensor(92.5124) tensor(98.8243) tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "150 tensor(91.9702) tensor(98.5099) tensor(1.2010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "200 tensor(92.0087) tensor(98.6007) tensor(1.1613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "250 tensor(92.1564) tensor(98.6305) tensor(1.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "300 tensor(92.3380) tensor(98.7126) tensor(1.1525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "350 tensor(92.2009) tensor(98.7179) tensor(1.2044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "400 tensor(92.2070) tensor(98.7219) tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "450 tensor(92.0732) tensor(98.7251) tensor(1.1451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500 tensor(92.0534) tensor(98.6901) tensor(1.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "0 tensor(100.) tensor(81.2500) tensor(1.2959, device='cuda:0')\n",
            "100 tensor(89.6658) tensor(96.6584) tensor(1.1654, device='cuda:0')\n",
            "Epoch 4, train_acc_sentiment: 0.9199410676956177, train_acc_topic: 0.9871070981025696, test_acc_sentiment: 0.8958742618560791, f1_sentiment: 0.895150525123625, test_acc_topic: 0.9646365642547607, f1_topic: 0.9648880657937953, epoch_time: 0:02:42.000719\n",
            "total training time:  0:10:10.676784\n"
          ]
        }
      ],
      "source": [
        "max_acc_sentiment = 0\n",
        "max_f1_sentiment = 0\n",
        "max_acc_topic = 0\n",
        "max_f1_topic = 0\n",
        "\n",
        "start_train = datetime.now()\n",
        "model = model.cuda()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_acc_sentiment = 0\n",
        "    train_acc_topic = 0\n",
        "    len_train = 0\n",
        "    model.train()\n",
        "    start_epoch = datetime.now()\n",
        "\n",
        "    for batch_idx, (input_ids, attention_mask, label_sentiment, label_topic) in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, label_sentiment, label_topic = input_ids.cuda(), attention_mask.cuda(), label_sentiment.cuda(), label_topic.cuda()\n",
        "            label_sentiment = F.one_hot(label_sentiment.reshape(-1), 3).float()\n",
        "            label_topic = F.one_hot(label_topic.reshape(-1), 4).float()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                predict_sentiment, predict_topic = model(input_ids, attention_mask)\n",
        "                loss = criterion(predict_sentiment, label_sentiment) + criterion(predict_topic, label_topic)\n",
        "            scaler.scale(loss).backward() #loss.backward()\n",
        "            scaler.step(optimizer) #optimizer.step()\n",
        "\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                    predict_sentiment = predict_sentiment.argmax(-1)\n",
        "                    predict_topic = predict_topic.argmax(-1)\n",
        "                    train_acc_sentiment += (predict_sentiment == label_sentiment.argmax(-1)).sum().cpu()\n",
        "                    train_acc_topic += (predict_topic == label_topic.argmax(-1)).sum().cpu()\n",
        "                    len_train += len(label_sentiment)\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(batch_idx, train_acc_sentiment / len_train * 100, train_acc_topic / len_train * 100, loss)\n",
        "\n",
        "            #break\n",
        "            #torch.cuda.empty_cache()\n",
        "\n",
        "    train_acc_sentiment = train_acc_sentiment / len_train\n",
        "    train_acc_topic = train_acc_topic / len_train\n",
        "\n",
        "    test_acc_sentiment = 0\n",
        "    test_acc_topic = 0\n",
        "    len_test = 0\n",
        "    model.eval()\n",
        "\n",
        "    test_labels_sentiment = []\n",
        "    test_predicts_sentiment = []\n",
        "    test_labels_topic = []\n",
        "    test_predicts_topic = []\n",
        "\n",
        "    for batch_idx, (input_ids, attention_mask, label_sentiment, label_topic) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label_sentiment, label_topic = input_ids.cuda(), attention_mask.cuda(), label_sentiment.cuda(), label_topic.cuda()\n",
        "            label_sentiment = F.one_hot(label_sentiment.reshape(-1), 3).float()\n",
        "            label_topic = F.one_hot(label_topic.reshape(-1), 4).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predict_sentiment, predict_topic = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict_sentiment, label_sentiment) + criterion(predict_topic, label_topic)\n",
        "\n",
        "                    predict_sentiment = predict_sentiment.argmax(-1)\n",
        "                    predict_topic = predict_topic.argmax(-1)\n",
        "\n",
        "                    test_acc_sentiment += (predict_sentiment == label_sentiment.argmax(-1)).sum().cpu()\n",
        "                    test_acc_topic += (predict_topic == label_topic.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label_sentiment)\n",
        "\n",
        "                    test_labels_sentiment += label_sentiment.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts_sentiment += predict_sentiment.cpu().numpy().tolist()\n",
        "\n",
        "                    test_labels_topic += label_topic.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts_topic += predict_topic.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc_sentiment / len_test * 100, test_acc_topic / len_test * 100, loss)\n",
        "\n",
        "    test_acc_sentiment = test_acc_sentiment / len_test\n",
        "    test_acc_topic = test_acc_topic / len_test\n",
        "\n",
        "    f1_sentiment = f1_score(test_predicts_sentiment, test_labels_sentiment, average = 'macro')\n",
        "    f1_topic = f1_score(test_predicts_topic, test_labels_topic, average = 'macro')\n",
        "\n",
        "    if test_acc_sentiment > max_acc_sentiment:\n",
        "        max_acc_sentiment = test_acc_sentiment\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"topic_max_acc_sentiment.pt\")\n",
        "\n",
        "    if f1_sentiment > max_f1_sentiment:\n",
        "        max_f1_sentiment = f1_sentiment\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"topic_max_f1_sentiment.pt\")\n",
        "\n",
        "    if test_acc_topic > max_acc_topic:\n",
        "        max_acc_topic = test_acc_topic\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"topic_max_acc_topic.pt\")\n",
        "\n",
        "    if f1_topic > max_f1_topic:\n",
        "        max_f1_topic = f1_topic\n",
        "        #checkpoint = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n",
        "        checkpoint = {'model': model.state_dict()}\n",
        "        torch.save(checkpoint, \"topic_max_f1_topic.pt\")\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch {epoch + 1}, train_acc_sentiment: {train_acc_sentiment}, train_acc_topic: {train_acc_topic}, test_acc_sentiment: {test_acc_sentiment}, f1_sentiment: {f1_sentiment}, test_acc_topic: {test_acc_topic}, f1_topic: {f1_topic}, epoch_time: {datetime.now() - start_epoch}')\n",
        "\n",
        "print('total training time: ', datetime.now() - start_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff0f35b",
      "metadata": {
        "papermill": {
          "duration": 0.034091,
          "end_time": "2024-06-24T12:23:41.450190",
          "exception": false,
          "start_time": "2024-06-24T12:23:41.416099",
          "status": "completed"
        },
        "tags": [],
        "id": "eff0f35b"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cd7e1c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:23:41.521500Z",
          "iopub.status.busy": "2024-06-24T12:23:41.521174Z",
          "iopub.status.idle": "2024-06-24T12:23:51.255294Z",
          "shell.execute_reply": "2024-06-24T12:23:51.254378Z"
        },
        "papermill": {
          "duration": 9.769924,
          "end_time": "2024-06-24T12:23:51.257625",
          "exception": false,
          "start_time": "2024-06-24T12:23:41.487701",
          "status": "completed"
        },
        "tags": [],
        "id": "88cd7e1c",
        "outputId": "df87702e-5713-4e7b-b025-8d90085c1f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(100.) tensor(0.5031, device='cuda:0')\n",
            "100 tensor(89.6658) tensor(0.5620, device='cuda:0')\n",
            "tensor(0.8959) 0.895150525123625\n"
          ]
        }
      ],
      "source": [
        "test_acc = 0\n",
        "len_test = 0\n",
        "\n",
        "model.load_state_dict(torch.load(\"topic_max_f1_sentiment.pt\")['model'])\n",
        "test_labels = []\n",
        "test_predicts = []\n",
        "\n",
        "for batch_idx, (input_ids, attention_mask, label, _) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 3).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predict, _ = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict, label)\n",
        "\n",
        "                    predict = predict.argmax(-1)\n",
        "                    test_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label)\n",
        "\n",
        "                    test_labels += label.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts += predict.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc / len_test * 100, loss)\n",
        "\n",
        "test_acc = test_acc / len_test\n",
        "f1 = f1_score(test_predicts, test_labels, average = 'macro')\n",
        "\n",
        "print(test_acc, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3daa03d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:23:51.323205Z",
          "iopub.status.busy": "2024-06-24T12:23:51.322903Z",
          "iopub.status.idle": "2024-06-24T12:23:51.335836Z",
          "shell.execute_reply": "2024-06-24T12:23:51.334909Z"
        },
        "papermill": {
          "duration": 0.047565,
          "end_time": "2024-06-24T12:23:51.337725",
          "exception": false,
          "start_time": "2024-06-24T12:23:51.290160",
          "status": "completed"
        },
        "tags": [],
        "id": "3daa03d8",
        "outputId": "16cc594f-142d-454e-a3f0-f75d60b1bad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8502    0.8765    0.8631       680\n",
            "           1     0.8576    0.8269    0.8419       670\n",
            "           2     0.9782    0.9825    0.9804       686\n",
            "\n",
            "    accuracy                         0.8959      2036\n",
            "   macro avg     0.8953    0.8953    0.8952      2036\n",
            "weighted avg     0.8958    0.8959    0.8957      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## label smoothing 0.2\n",
        "print(sklearn.metrics.classification_report(test_labels, test_predicts, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e782f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:23:51.402324Z",
          "iopub.status.busy": "2024-06-24T12:23:51.402057Z",
          "iopub.status.idle": "2024-06-24T12:24:01.121326Z",
          "shell.execute_reply": "2024-06-24T12:24:01.120409Z"
        },
        "papermill": {
          "duration": 9.754008,
          "end_time": "2024-06-24T12:24:01.123545",
          "exception": false,
          "start_time": "2024-06-24T12:23:51.369537",
          "status": "completed"
        },
        "tags": [],
        "id": "04e782f1",
        "outputId": "e9de4fc1-9650-458f-8776-aadda3737561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor(81.2500) tensor(0.7928, device='cuda:0')\n",
            "100 tensor(96.6584) tensor(0.6034, device='cuda:0')\n",
            "tensor(0.9646) 0.9648880657937953\n"
          ]
        }
      ],
      "source": [
        "test_acc = 0\n",
        "len_test = 0\n",
        "\n",
        "model.load_state_dict(torch.load(\"topic_max_f1_topic.pt\")['model'])\n",
        "test_labels = []\n",
        "test_predicts = []\n",
        "\n",
        "for batch_idx, (input_ids, attention_mask, _, label) in enumerate(test_dataloader):\n",
        "            input_ids, attention_mask, label = input_ids.cuda(), attention_mask.cuda(), label.cuda()\n",
        "            label = F.one_hot(label.reshape(-1), 4).float()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    _, predict = model(input_ids, attention_mask)\n",
        "                    loss = criterion(predict, label)\n",
        "\n",
        "                    predict = predict.argmax(-1)\n",
        "                    test_acc += (predict == label.argmax(-1)).sum().cpu()\n",
        "                    len_test += len(label)\n",
        "\n",
        "                    test_labels += label.argmax(-1).cpu().numpy().tolist()\n",
        "                    test_predicts += predict.cpu().numpy().tolist()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(batch_idx, test_acc / len_test * 100, loss)\n",
        "\n",
        "test_acc = test_acc / len_test\n",
        "f1 = f1_score(test_predicts, test_labels, average = 'macro')\n",
        "\n",
        "print(test_acc, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7084833a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-24T12:24:01.191880Z",
          "iopub.status.busy": "2024-06-24T12:24:01.191171Z",
          "iopub.status.idle": "2024-06-24T12:24:01.204269Z",
          "shell.execute_reply": "2024-06-24T12:24:01.203186Z"
        },
        "papermill": {
          "duration": 0.049542,
          "end_time": "2024-06-24T12:24:01.206129",
          "exception": false,
          "start_time": "2024-06-24T12:24:01.156587",
          "status": "completed"
        },
        "tags": [],
        "id": "7084833a",
        "outputId": "cfa71c17-53ea-4fe3-d106-4099e51642d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9478    0.9658    0.9567       526\n",
            "           1     0.9766    0.9728    0.9747       515\n",
            "           2     0.9438    0.9270    0.9353       507\n",
            "           3     0.9918    0.9939    0.9928       488\n",
            "\n",
            "    accuracy                         0.9646      2036\n",
            "   macro avg     0.9650    0.9649    0.9649      2036\n",
            "weighted avg     0.9646    0.9646    0.9646      2036\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## label smoothing 0.2\n",
        "print(sklearn.metrics.classification_report(test_labels, test_predicts, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa697262",
      "metadata": {
        "papermill": {
          "duration": 0.032309,
          "end_time": "2024-06-24T12:24:01.270996",
          "exception": false,
          "start_time": "2024-06-24T12:24:01.238687",
          "status": "completed"
        },
        "tags": [],
        "id": "aa697262"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3052448,
          "sourceId": 5245967,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1833.996509,
      "end_time": "2024-06-24T12:24:03.982271",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-06-24T11:53:29.985762",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}